<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Protobuf数据格式解析]]></title>
    <url>%2F2018%2F02%2F24%2FProtobuf%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[一、Protobuf介绍Protobuf是Google开源的一款类似于Json，XML数据交换格式，其内部数据是纯二进制格式，不依赖于语言和平台，具有简单，数据量小，快速等优点。目前用于序列化与反序列化官方支持的语言有C++，C#， GO， JAVA，PYTHON。 二、定义消息文件.proto123456789101112option java_outer_classname = "ConditionItems";message ConditionItemsProto &#123; repeated ConditionItemProto items = 1; message ConditionItemProto &#123; required string statusCode = 1; optional int32 sts = 2; required string scateCode = 3; optional string val = 4; &#125;&#125; 说明：–java_outer_classname 生成数据访问类类名–required 必填字段，在后面的使用中必须赋值–optional 可选字段，在后面的使用中可自由选择是否赋值 三、使用protobuf的编译器编译消息文件3.1 安装Protobuf1、首先去GitHub上下载项目，解压2、如果你是Windows环境，则还要下载多一个东西。protobuf-x.x.x-windows.zip。(x.x.x代表版本号)下载地址：https://developers.google.com/protocol-buffers/docs/downloads选择版本如图所示：3、解压protobuf-x.x.x-windows.zip，把bin目录下的protoc.exe放在protobuf-master安装目录下的src里 3.2 配置环境变量编辑系统变量Path，添加Protoc.exe的存放目录。（也就是protobuf-master安装目录下的src目录）检查环境变量是否配置成功 3.3 使用protoc.exe编译成java类直接打开cmd运行命令，命令如下： 1protoc.exe -I=proto的输入目录 --java_out=java类输出目录 proto的输入目录包括包括proto文件 生成ConditionItems.java 四、解析利用这个生成的java文件编写测试类进行DtcItemsProto对象的属性填充后对其进行序列化和反序列化测试，具体代码如下 1234567891011ConditionItems.ConditionItemsProto.Builder builderAll = ConditionItems.ConditionItemsProto.newBuilder();ConditionItems.ConditionItemsProto.ConditionItemProto.Builder builder = ConditionItems.ConditionItemsProto.ConditionItemProto.newBuilder();builder.setStatusCode("status");builder.setSts(1);builder.setScateCode("scate");builder.setVal("value");builderAll.addItems(builder);ConditionItems.ConditionItemsProto info = builderAll.build();byte[] result = info.toByteArray();ConditionItems.ConditionItemsProto testBuf = ConditionItems.ConditionItemsProto.parseFrom(result);System.out.println(testBuf); 以上就是对protobuf的序列化和反序列化的过程]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>Protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch——通过Hive将数据写入到ElasticSearch]]></title>
    <url>%2F2018%2F02%2F23%2FElasticSearch%E2%80%94%E2%80%94%E9%80%9A%E8%BF%87Hive%E5%B0%86%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E5%88%B0ElasticSearch%2F</url>
    <content type="text"><![CDATA[一、准备下载hive与es之间数据交互的插件 说明：为了避免因为版本问题报错，在这里我选择的是和服务器ElasticSerch版本一致的依赖包，版本号为elasticsearch-hadoop-6.1.3.jar 二、开发2.1、将第三方jar包添加到hive中：1hive&gt; add jar /home/elasticsearch-hadoop-6.1.3.jar; 2.2、创建Hive外部表1234567891011121314151617181920create table db_source_hbase_timadmp_statistics_day( vin string, imei string, item_code string, item_value string, statistics_date timestamp) partitioned by(dt string)STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler'TBLPROPERTIES('es.nodes' = '172.20.30.38','es.port'='9200','es.nodes.wan.only'='true','es.resource' = 'statistics/day','es.mapping.names' = 'vin:vin,imei:imei,item_code:item_code,item_value:item_value,statistics_date:statistics_date'); 说明：这里指定es的端口号为9200 2.3、往Hive表里面插入数据1insert into table db_source_hbase_timadmp_statistics_day PARTITION (dt = '2018-02-13') values('test_vin', 'test_iemi', 'test_item_code', 'test_item_value', '1517810143'); 插入成功过后通过ElasticSearch的head插件查看刚才插入的数据是否同步到了ESmapping如下： 1234567891011121314&#123;"_index": "statistics","_type": "day","_id": "nbkFjmEBCT8i1sV5YQjE","_version": 1,"_score": 1,"_source": &#123;"vin": "test_vin","imei": "test_iemi","item_code": "test_item_code","item_value": "test_item_value","statistics_date": null&#125;&#125; 说明：从这里发现Hive表里面的字段，类型都对应了。但是我们发现ElasticSearch中的 statistics/day 每行数据对应的id都是随机生成的，不过我们可以在建Hive表的时候加上 es.mapping.id 参数来指定我们自定义的id 三、总结在同步数据时，分为两种情况1、先有Elasticsearch再有Hive在ElasticSearch中已有索引和类型，甚至在其中存储有数据时，我们可以在Hive中直接对ElasticSearch中数据进行操作2、先有Hive再有Elasticsearch当Elasticsearch中不存在相应索引时，经过执行插入语句，在Elasticsearch中就会创建一个新索引：indexname，新类型：typename（当然是在Hive创建新外部表时指定好的），数据也已经添加入其中。]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch——Java连接篇]]></title>
    <url>%2F2018%2F02%2F06%2FElasticSearch%E2%80%94%E2%80%94Java%E8%BF%9E%E6%8E%A5%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一、ElasticSearch介绍：Elasticsearch是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单 二、为什么要用ES：实际项目开发实战中，几乎每个系统都会有一个搜索的功能，当搜索做到一定程度时，维护和扩展起来难度就会慢慢变大，所以很多公司都会把搜索单独独立出一个模块，用ElasticSearch等来实现。近年ElasticSearch发展迅猛，已经超越了其最初的纯搜索引擎的角色，现在已经增加了数据聚合分析（aggregation）和可视化的特性，如果你有数百万的文档需要通过关键词进行定位时，ElasticSearch肯定是最佳选择。当然，如果你的文档是JSON的，你也可以把ElasticSearch当作一种“NoSQL数据库”， 应用ElasticSearch数据聚合分析（aggregation）的特性，针对数据进行多维度的分析 三、开发3.1 添加POM依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.1.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;6.1.3&lt;/version&gt;&lt;/dependency&gt; 注意：jar包版本最好和服务器部署的ES版本相同。否则会报错，错误信息如下（亲身试验）： 1Exception in thread "main" NoNodeAvailableException[None of the configured nodes are available 3.2 Java Client 连接 ES123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Componentpublic class EsClient &#123; static TransportClient client = null; public EsClient()&#123; try&#123; //没有设置集群名称，则默认Settings.EMPTY client = new PreBuiltTransportClient(Settings.EMPTY) .addTransportAddress(new TransportAddress(InetAddress.getByName("127.0.0.1"), 9300)); &#125;catch (Exception ex)&#123; client.close(); &#125;finally &#123; &#125; &#125; public static TransportClient getConnection()&#123; if (client==null)&#123; synchronized (EsClient.class)&#123; if (client==null)&#123; new EsClient(); &#125; &#125; &#125; return client; &#125; public static void main(String[] args) &#123; //设置要查询的索引(index) String index="myindex"; //设置type, 这个在建立索引的时候同时设置了, 或者可以使用head工具查看 String type="external"; SearchResponse response=EsClient.getConnection().prepareSearch(index) .setSearchType(SearchType.DFS_QUERY_THEN_FETCH) .setTypes(type) //这里是设置查询条件等等 .setQuery(QueryBuilders.matchAllQuery()) .setFrom(0) .setSize(10) .setExplain(true) .execute() .actionGet(); for(SearchHit hit:response.getHits())&#123; System.out.println(hit.getSourceAsString()); &#125; &#125;&#125;``` 注意：如果安装部署ElasticSearch的时候没有单独配置端口号，则默认9300端口（9200是restful方式调用的端口）； 四、踩坑记录除了在上面提到的注意事项，还有某些坑是在开发过程中发现总结的；1、如果在ES的配置中改了集群名字，需要在连接ES的设置集群名称123Settings settings = Settings.builder() .put("client.transport.sniff", true) .put("cluster.name", "elasticsearch").build(); 2、如果发现连接不上，检查服务器防火墙策略]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 单元测试——Mock]]></title>
    <url>%2F2018%2F01%2F12%2FSpring-Boot-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E2%80%94%E2%80%94Mock%2F</url>
    <content type="text"><![CDATA[一、场景介绍：在很多业务场景中，我们需要远程调用另一个微服务上面的接口；很多时候我们并不能在单元测试中去真实的远程调用其他接口，但是业务上却依赖其他接口的返回值。所以我们需要模拟外部依赖，这时就需要用到Mock测试 二、目标：在测试过程中，对那些不容易构建的对象用一个虚拟对象来代替测试 三、过程3.1 添加POM依赖123456&lt;dependency&gt; &lt;groupId&gt;org.mockito&lt;/groupId&gt; &lt;artifactId&gt;mockito-all&lt;/artifactId&gt; &lt;version&gt;1.8.5&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 3.2 Junit单元测试@RunWith(SpringJUnit4ClassRunner.class) @SpringBootTest(classes = CommonApplication.class) @FixMethodOrder(MethodSorters.NAME_ASCENDING) public class MockServiceTest{ //@Mock @Autowired IService iService; @Test public void btestService(){ //创建mock对象，参数可以是类，也可以是接口 iService = mock(IService.class); //设置方法的预期返回值 when(iService.getHelloWorld()).thenReturn("Test"); String result = iService.getHelloWorld(); //junit测试 Assert.assertEquals("Test", result); } } 注意：@Mock注解会和@Autowired冲突，导致注入失败，不能两个注解同时出现。所以采用这种方法object = mock(object.class); 创建mock对象不能对final，Anonymous ，primitive类进行mock.(网上写的，未做实验)]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>Mock</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 单元测试——H2数据库配置]]></title>
    <url>%2F2018%2F01%2F12%2FSpring-Boot-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E2%80%94%E2%80%94H2%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[一、场景介绍：在写单元测试时，我们往往会遇到一个问题，测试用例所依赖的数据库数据被修改或删除了，或者在一个新的环境下所依赖的数据库不存在，导致单元测试无法通过，进而构建失败。在这种情况下，使用H2内存数据库来模拟数据库环境是一个很好的解决方案 二、目标：当我们运行单元测试时，不依赖业务相关数据库，避免数据库正常数据被删除或修改导致业务运行异常 三、过程3.1 添加POM依赖12345&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId &gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;1.4.192&lt;/version&gt;&lt;/dependency&gt; 3.2 添加数据库配置123456789spring: datasource: name: h2 url: jdbc:h2:mem:testdb;MODE=MYSQL;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE;INIT=RUNSCRIPT FROM './src/test/resources/init_table.sql'; username: root password: driver-class-name: org.h2.Driver jpa: show-sql: true 1、这里面的INIT=RUNSCRIPT，这里用来初始化init_table.sql脚本的；比如某些测试用例需要初始数据，这时就需要在运行测试用例之前执行初始化SQL脚本。2、MODE=MySql ，以mysql的模式运行3、DB_CLOSE_DELAY=-1 关闭参数，延时关闭为代码退出时间。4、jdbc:h2:mem 意思使用h2的内存数据库版本，还可以有file等各种方式 3.3 编写数据库实体类1234567891011@Entitypublic class User &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; @Column private String name; ...这里省略了getter，setter方法，实际运用需要加上&#125; 3.4 编写数据访问层接口123@Repositorypublic interface UserRepository extends JpaRepository&lt;User, Long&gt;&#123;&#125; 3.5 Junit单元测试123456789101112131415@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = CommonApplication.class)@FixMethodOrder(MethodSorters.NAME_ASCENDING)public class MockServiceTest&#123; @Autowired IService iService; @Test public void save()&#123; User user = new User(); user.setName("TEST"); iService.save(user); &#125;&#125; 四、运行结果 五、总结从日志中可以看出，由于H2是关系内存数据库，当程序启动的时候，会在内存中创建表，并将数据存储在内存中，当重启程序后，会自动删除内存中的数据，从而可以很好的用来做dao层的单元测试和service层的单元测试，使整个程序不会依赖具体的数据库，同时也提高了单元测试的效率。]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>H2</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOs6.7下部署ShowDoc文档工具]]></title>
    <url>%2F2017%2F09%2F19%2FCentOs6-7%E4%B8%8B%E9%83%A8%E7%BD%B2ShowDoc%E6%96%87%E6%A1%A3%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[准备 Nginx + PHP 环境安装 Nginx使用 yum 安装 Nginx： yum install nginx修改 /etc/nginx/nginx.conf 文件为如下内容： user nginx; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid; include /usr/share/nginx/modules/*.conf; events { worker_connections 1024; } http { log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; include /etc/nginx/conf.d/*.conf; server { listen 80; server_name 127.0.0.1; root /var/www/html; index index.php index.html error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } location ~ .php$ { root /var/www/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } location ~ /.ht { deny all; } } } 启动 Nginx 并设置为开机启动： service nginx startchkconfig nginx on 安装 PHP使用 yum 安装 php-fpm：yum install php php-gd php-fpm php-mcrypt php-mbstring php-mysql php-pdo 启动 php-fpm 并设置为开机启动： service php-fpm startchkconfig php-fpm on 创建项目下载安装 ComposerComposer 是 PHP 的一个依赖管理工具，推荐使用 Composer 创建 ShowDoc 项目。 安装 Composer：curl -sS https://getcomposer.org/installer | php mv composer.phar /usr/local/bin/composer 设置 Composer 使用国内镜像执行命令：composer config -g repo.packagist composer https://packagist.phpcomposer.com 使用 Composer 创建项目执行命令创建项目：cd /var/www/html/ &amp;&amp; composer create-project showdoc/sh 设置 showdoc 目录写权限执行命令赋予 showdoc 下部分目录的写权限 chmod a+w showdoc/installchmod a+w showdoc/Sqlitechmod a+w showdoc/Sqlite/showdoc.db.phpchmod a+w showdoc/Public/Uploadschmod a+w showdoc/Application/Runtimechmod a+w showdoc/server/Application/Runtimechmod a+w showdoc/Application/Common/Conf/config.phpchmod a+w showdoc/Application/Home/Conf/config.php 创建完毕，您现在可以通过浏览器访问 http://ip/showdoc/install/ ，进行语言的选择以后即可通过 http://ip/showdoc 查看站点效果。]]></content>
      <tags>
        <tag>ShowDoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala学习之路（一）]]></title>
    <url>%2F2017%2F09%2F15%2FScala%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud 学习--使用WebHooks自动更新配置中心]]></title>
    <url>%2F2017%2F08%2F30%2FSpring-Cloud-%E5%AD%A6%E4%B9%A0-%E4%BD%BF%E7%94%A8WebHooks%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[一、场景介绍：配置服务中心采用Git的方式存储配置文件 每次更改配置后，都需要重启服务或者分别的发送POST请求才能更新配置 二、目标：当我们更新Git仓库的配置信息的时候，所有使用了修改的配置的服务都会刷新配置 三、过程3.1 安装RabbitMQ由于会用到spring cloud的amqp，所以需要安装RabbitMQ，在这里安装RabbitMQ的安装过程就不再多说了， 安装教程参考CentOS7下RabbitMQ服务安装配置 3.2 Quick StartSpring cloud config 分为两部分1、config-server 配置服务端，服务管理配置信息2、config-client 客户端，客户端调用server端暴露接口获取配置信息你需要做的就是使spring-cloud-starter-bus-amqp或spring-cloud-starter-bus-kafka添加到你的config-server和config-client依赖管理中 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; Spring Cloud将完成剩下的事。你唯一需要的事是确定broker (RabbitMQ or Kafka) 可用如Rabbit在application.yml（或bootstrap.yml）中添加如下配置信息 123456spring: rabbitmq: host: mybroker.com port: 5672 username: user password: secret 启动config-server和config-client到这里，我们已经能够通过/bus/refresh来实时更新总线上的属性配置了，但是每次更新配置都需要手动去执行一下POST请求，这肯定不是我们最终的目的，所以这里就要用到git的webhooks来达到自动更新配置 3.3 WebHooks打开gitlab上配置仓库的地址，添加webhooks（URL填写填写我们的配置中心触发刷新的地址，前提是必须git能够访问的到ip和端口。这样只要git仓库有push操作，便会触发配置中心的刷新地址，达到自动更新配置的目的） 四、原理分析通过使用Spring Cloud Bus与Spring Cloud Config的整合，并以RabbitMQ作为消息代理，实现了应用配置的动态更新 本文参考 Spring-cloud WikiSpring Cloud构建微服务架构（七）消息总线]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>WebHooks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用git命令整理]]></title>
    <url>%2F2017%2F03%2F06%2F%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[一、生成本地仓库在本地生成一个仓库(一般就是一个项目等)A：本地初始化一个文件夹为一个仓库，让git把这个文件夹当作一个仓库进行操作 1) git init 2) git remote add origin git@github.com:Andrew/Test.git 为刚刚初始化的仓库添加一个远程仓库联系，这样我们就能把本地的代码提交到远程了哈 B：直接在本地clone一个远程仓库，即把远程仓库的所有受管理文件复制到本地，然后进入仓库根目录就可以进行相关操作，比如修改(编写自己的代码)，推送(更新自己的代码到远程服务器) 1) git clone git@github.com:Andrew/Test.git 2) cd Test 现在就能在修改clone下的仓库(Test里面)下面的文件了。 二、对本地仓库内容进行修改A：git在本地修改时是基于branch进行操作的，每个branch可以保留不一样的副本 1) 新建分支: git branch branch_name 2) 查看本地所有分支列表: git branch -a 3) 切换到要进行操作的分支: git checkout branch_name 4) 跳过创建分支的步骤，直接创建(clone当前分支)并切换到新分支: git checkout -b branch_name 5) 跳过创建分支的步骤，直接创建(以指定的tag为分支版本)并切换到新分支: git checkout -b branch_name tag_name B：在当前分支上，对受管理的文本文件做一些修改，然后就可以commit到当前分支上 1) 先把修改添加到缓存: git add file_url_name (只是添加一个文件，git add . 命令可以把当前分支上的所有修改添加到缓存) 2) 把已经添加到缓存的内容进行commit: git commit -m “commit_content” 3) 此时就可以把当前分支的内容进行推送或者检出打包，合并等操作了。 三、提交本地代码到远程仓库命令： git push [remote_name] [local_branch]:[remote_brnach]命令的含义：把本地的[local_branch]上的内容更新到[remote_name]仓库的[remote_brnach]上面remote_name-&gt;某个远端的remote地址在本地对应的名称；local_branch-&gt;本地仓库的某个分支名称；remote_brnach-&gt;远端仓库的某个分支名称；注：上面命令可以简写为 “git push”,默认为 “oringin, local/master, origin/master”, 设置本地的某个分支为本地的master分支的命令是：git push –set-upstream oringin/master 四、推送内容和拉取远程的内容到本地1) git push [remote_name] [local_branch]:[remote_brnach] 2) git pull [remote_name] [remote_brnach]:[local_branch] 3) git fetch [remote_name] [remote_brnach]:[local_branch] 五、本地修改的相关操作1) 取消对文件的修改。放弃未提交的修改，还原到最后一次commit后的状态。 git checkout – [file-path-name] 2) 还原被加入缓存状态文件的状态。即，撤销之前的add file-path-name 操作 git reset – [file-path-name] (git reset HEAD – [file-path-name]) 3) 还原所有被加入缓存状态文件的状态。即，撤销之前的add . 操作 git reset (git reset HEAD) 4) 撤销本地某个文件的修改 git checkout – filename 5) 撤销所有本地文件的修改 git checkout – . (git checkout .) 6) 当前工作区内容不变,但是暂存区会回退到上一次提交之前 git reset head^ 7) 回退某个文件的版本到上一个版本 git reset HEAD^ [file-path-name] 8) 向前回退到第X个版本 git reset –soft HEAD~3 9) 将本地的状态回退到和远程的某个分支一样 git reset –hard origin/master 10) 回退到某个具体的版本 git reset version-number 六、回滚本地提交1) git reset –hard commit-id: 强制把当前分支回滚到所指定的commit记录 git reset –hard HEAD~3: 将最近3次的提交回滚 2) git reset –soft head^: 将最近1次的提交软回滚 git reset –soft head~3:将最近3次的提交软回滚 注: hard方式的回滚会直接抹消被回滚的commit的修改;而soft方式的话，只会把当前分支的commit指向回滚到的位置，然后被回滚的所有commit的修改会依然保存在本地，以git缓存的方式存在; 七、合并冲突1) git merge [branch_name] 把当前分支与目标分支合并 把当前分支的内容与目标分支的内容进行对比列出区别 手动解决冲突后进行commit，所以最后会有一个“Merge branch”的commit 解决完冲突后，在commi历史中会多一个merge的commit，里面可能包含一些冲突解决时代码的取舍痕迹。 2) git rebase [branch_name] 把当前分支与目标分支合并，把当前分支超前的commit追加到目标分支的commit之后 解决完冲突后，在commit历史上看不出有合并的痕迹。 八、合并时，如果有冲突如何解决?1)在使用 “git rebase”命令时,当不能顺利的进行合并时，那就是有冲突了，这个时候 就定位到两个分支有冲突的公共地方，主动的进行取舍保留，确定好要保存的版本快照 后，回到命令行，执行 “git add .”把解决分支产生的修改添加到缓存中，然后再执行 “git rebase –continue” 2)在使用 “git am”命令时,当不能顺利的把补丁文件应用到当前分支上时， 那就是有冲突了，这个时候就定位到有冲突的公共地方，主动的进行取舍保留，确定好要保存的版本快照后， 回到命令行，执行 “git add.”把解决分支产生的修改添加到缓存中，然后再执行 “git am –continue” 九、查看历史提交的commit内容1) git log : 显示当前分支的历史commit内容. 2) git log –stat : 显示当前分支的历史commit内容和每次commit对应修改了哪些文件 十、git stash，强大的当前工作状态暂存方式应用场景:比如自己正在开发一个功能,突然接到修改一个紧急bug的任务, 就可以先暂存自己的工作状态, 修改完bug后, 返回到自己的工作进度. 1) git stash save “name” 把当前工作目录的所有修改添加到一个stash记录里面. 2) git stash pop “stash-index” 把某个index的stash记录加载(弹出)到当前工作目录(同时stash列表里移除对应的记录) 3) git stash apply “name” 把某个index的stash记录加载(应用)到当前工作目录(同时stash列表里依旧保留对应的记录)。 4) git stash drop “stash-index” 移除掉某个index对应的stash记录。]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下安装minecraft服务器]]></title>
    <url>%2F2015%2F09%2F24%2FLinux%E4%B8%8B%E5%AE%89%E8%A3%85minecraft%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1.创建一个MC服务器的目录并且切换过去2.下载MC服务器的压缩包1https://s3.amazonaws.com/Minecraft.Download/versions/1.7.10/minecraft_server.1.7.10.jar 重命名 1# cp minecraft_server.jar minecraft_server.1.7.10.jar 3.启动服务器（由于阿里云内存只有1G，所以这里分配的512M）1java -Xmx512M -Xms512M -jar minecraft_server.jar nogui 然后会出现如下错误： 解决办法： vim eula.txt eula=true (默认是false) vim server.properties online-mode=false 重新启动服务器（出现如下的log说明启动成功） 4、为了启动方便我们自己编写一下启动的shell文件在minecraft安装目录下新建一个 start.sh shell命令如下： #!/bin/bash cd /usr/minecraft/ eval java -Xmx512M -Xms512M -jar minecraft_server.1.7.10.jar nogui &amp;]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>Minecraft</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyEclipse 内存溢出异常解决]]></title>
    <url>%2F2015%2F06%2F19%2FMyEclipse-%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%BC%82%E5%B8%B8%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[1.使用本地JDK，并配置内存分配 2.给MyEclipse分配合理的java虚拟机内存在MyEclipse安装目录X:\MyEclipse\MyEclipse10下的myeclipse.ini的文件中添加如下内容。 12345678-vmargs-Xms1500m-Xmx2048m-XX:MaxPermSize=1024m-XX:ReservedCodeCacheSize=512m-XX:PermSize=512M-XX:MaxPermSize=1024M-Dosgi.nls.warnings=ignore 重启MyEclipse即可]]></content>
      <categories>
        <category>技术文档</category>
      </categories>
      <tags>
        <tag>MyEclipse</tag>
      </tags>
  </entry>
</search>
